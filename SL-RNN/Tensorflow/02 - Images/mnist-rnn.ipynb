{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST using RNN\n",
    "\n",
    "Also check https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf20_RNN2/full_code.py\n",
    "\n",
    "And https://www.youtube.com/watch?v=SeffmcG42SY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "* Import the library to use.\n",
    "* This example uses tensorflow.\n",
    "* Datasets use the mnist dataset provided by tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf \n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "tf.reset_default_graph()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "* Load the dataset you want to use.\n",
    "* Images: Monochrome images written in cursive from 0 to 9 (1 channel).\n",
    "* Label: Set to one_hot format.\n",
    "\n",
    "- 0 = [1 0 0 0 0 0 0 0 0 0]\n",
    "- 1 = [0 1 0 0 0 0 0 0 0 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Number of train data is 55000\n",
      "Number of test data is 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "print(\"Number of train data is %d\" % (mnist.train.num_examples))\n",
    "print(\"Number of test data is %d\" % (mnist.test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed for comparing results\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the dataset\n",
    "\n",
    "Check the image and label of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAeCmWUOBDPLHAhmljkQzCz7f1L4O3CmdPwLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bffe940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nsample = 1\n",
    "rand_idx = np.random.randint(mnist.train.images.shape[0], size=nsample)\n",
    "\n",
    "for i in rand_idx:\n",
    "    curr_img = np.reshape(mnist.train.images[i, :], (28,28))\n",
    "    curr_lbl = np.argmax(mnist.train.labels[i, :])\n",
    "    plt.matshow(curr_img, cmap=plt.get_cmap('gray'))\n",
    "    plt.title(\"\"+str(i)+\"th training image \"\n",
    "              + \"(label: \" + str(curr_lbl) + \")\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring RNNs for Image Classification\n",
    "\n",
    "Configure the 28x28 image as shown below for RNN input.\n",
    "\n",
    "* Input_vec_size: Use one of the images (28x28) as an input to the RNN.\n",
    "* Time_step_size: 28 lines are required to enter a single image (28x28). Therefore, time_step is 28.\n",
    "* Lstm_size: number of hidden units in the rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "#                        O * W + b -> 10 labels for each image, O[? 28], W[28 10], B[10]\n",
    "#                       ^ (O: output 28 vec from 28 vec input)\n",
    "#                       |\n",
    "#      +-+  +-+       +--+\n",
    "#      |1|->|2|-> ... |28| n_steps = 28\n",
    "#      +-+  +-+       +--+\n",
    "#       ^    ^    ...  ^\n",
    "#       |    |         |\n",
    "# img1:[28] [28]  ... [28]\n",
    "# img2:[28] [28]  ... [28]\n",
    "# img3:[28] [28]  ... [28]\n",
    "# ...\n",
    "# img128 or img256 (batch_size or test_size 128 or 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "n_epochs_experiment1 = 40000 \n",
    "n_epochs_experiment2 = 5\n",
    "lr = 0.001\n",
    "decay = 0.9\n",
    "\n",
    "batch_size = 256 \n",
    "\n",
    "n_inputs = 28   # MNIST data input or chunk_size (img shape: 28*28)\n",
    "n_steps = 28    # time_step_size or n_chunks\n",
    "\n",
    "n_hidden_units = 128 #Is the LSTM size\n",
    "\n",
    "n_classes = 10 #MNIST classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recurrent_neural_network(x):\n",
    "    layer = {'weights':tf.Variable(tf.random_normal([n_hidden_units,n_classes])),\n",
    "             'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    x = tf.transpose(x, [1,0,2])\n",
    "    x = tf.reshape(x, [-1, n_inputs])\n",
    "    x = tf.split(axis=0, num_or_size_splits=n_inputs, value=x)\n",
    "\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units)\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    output = tf.matmul(outputs[-1],layer['weights']) + layer['biases']\n",
    "\n",
    "    return output, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion\n",
    "\n",
    "* Reshape training and test data from 1d to 2d.\n",
    "* Declare a placeholder for input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "trX = trX.reshape(-1, n_steps, n_inputs)\n",
    "teX = teX.reshape(-1, n_steps, n_inputs)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) # size (128,28,28)\n",
    "Y = tf.placeholder(tf.float32, [None, n_classes])         # size (128,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "* Generate model for size of hidden unit and output unit\n",
    "* Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_x, state_size = recurrent_neural_network(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and optimize the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))\n",
    "#optimizer = tf.train.RMSPropOptimizer(lr, decay).minimize(cost)\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "#predict_op = tf.argmax(py_x, 1)\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(py_x,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the model\n",
    "\n",
    "* There are two examples on how to train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2560, Minibatch Loss= 1.777941, Training Accuracy= 0.39062\n",
      "Iter 5120, Minibatch Loss= 1.480698, Training Accuracy= 0.49219\n",
      "Iter 7680, Minibatch Loss= 1.174730, Training Accuracy= 0.57031\n",
      "Iter 10240, Minibatch Loss= 1.026648, Training Accuracy= 0.65625\n",
      "Iter 12800, Minibatch Loss= 0.849184, Training Accuracy= 0.71484\n",
      "Iter 15360, Minibatch Loss= 0.656576, Training Accuracy= 0.80078\n",
      "Iter 17920, Minibatch Loss= 0.600989, Training Accuracy= 0.76562\n",
      "Iter 20480, Minibatch Loss= 0.562003, Training Accuracy= 0.82031\n",
      "Iter 23040, Minibatch Loss= 0.393789, Training Accuracy= 0.89453\n",
      "Iter 25600, Minibatch Loss= 0.321680, Training Accuracy= 0.89062\n",
      "Iter 28160, Minibatch Loss= 0.242234, Training Accuracy= 0.92969\n",
      "Iter 30720, Minibatch Loss= 0.273883, Training Accuracy= 0.91016\n",
      "Iter 33280, Minibatch Loss= 0.329709, Training Accuracy= 0.91016\n",
      "Iter 35840, Minibatch Loss= 0.399643, Training Accuracy= 0.87891\n",
      "Iter 38400, Minibatch Loss= 0.404943, Training Accuracy= 0.88281\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.929688\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "display_step = 10\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < n_epochs:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_inputs))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={X: batch_x, Y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={X: batch_x, Y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_inputs))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n",
    "    \n",
    "    \n",
    "    \n",
    "    predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.941406\n",
      "1 0.945312\n",
      "2 0.980469\n",
      "3 0.976562\n",
      "4 0.96875\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "test_size = 256\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        for start, end in zip(range(0, len(trX), batch_size), range(batch_size, len(trX)+1, batch_size)):\n",
    "            sess.run(optimizer, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "\n",
    "        test_indices = np.arange(len(teX))  # Get a Test Batch\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:test_size]\n",
    "\n",
    "        print(i, sess.run(accuracy, feed_dict={X: teX[test_indices], Y: teY[test_indices]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
